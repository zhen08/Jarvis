# MacOS Chat Assistant

A native macOS chat assistant application that uses Ollama for local LLM services.

## Features

- Native SwiftUI macOS application
- Modern, clean interface
- Support for multiple Ollama models
- Real-time chat interface
- Automatic model detection
- Error handling and status feedback

## Prerequisites

1. Install Ollama from [https://ollama.ai](https://ollama.ai)
2. Pull your desired models using Ollama CLI (e.g., `ollama pull llama2`)
3. Make sure Ollama service is running

## Development

1. Open the project in Xcode
2. Build and run the project (âŒ˜R)

## Usage

1. Start the Ollama service
2. Launch the Chat Assistant app
3. Select a model from the dropdown menu
4. Type your message and click the send button or press Return

## Requirements

- macOS 14.0 or later
- Xcode 15.0 or later
- Ollama installed and running locally 